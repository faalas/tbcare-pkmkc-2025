{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otm52twqjLBi",
        "outputId": "f8b40304-f298-48f5-d5b6-0cfc107776c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import**"
      ],
      "metadata": {
        "id": "2zhIzJJJcmvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.signal import lfilter\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/[3] Model ML TBCare/')\n",
        "import speechproc"
      ],
      "metadata": {
        "id": "yoOsaN4UjWp7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Metadata Exploration**"
      ],
      "metadata": {
        "id": "hhSrqPDcisdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Metadata**"
      ],
      "metadata": {
        "id": "rf7WRtEpmfDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia/Metadata and Codebook/GHAI_Final_Data_2023.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQiXE4c0jOaM",
        "outputId": "01eb1be9-e6c4-45fd-ec0c-4816d4a31bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  consent_obtained      barcode  coughdur cough_productive  \\\n",
              "0      m                 1  01-399-0258    1-2wks              yes   \n",
              "1      m                 1  01-399-1081      <1wk              yes   \n",
              "2      m                 1  02-399-0856      <1wk              yes   \n",
              "3      f                 1  03-399-0290    1-2wks              yes   \n",
              "4      m                 1  01-399-0744      <1wk              yes   \n",
              "...   ..               ...          ...       ...              ...   \n",
              "1823   f                 1  02-399-0239  no cough              NaN   \n",
              "1824   f                 1  02-399-0214      <1wk              yes   \n",
              "1825   m                 1  01-399-0973      <1wk              yes   \n",
              "1826   m                 1  02-399-0711   >4weeks              yes   \n",
              "1827   f                 1  03-399-0118    3-4wks              yes   \n",
              "\n",
              "     haemoptysis chestpain shortbreath fever ngtsweats  ... tb_class_index  \\\n",
              "0             no       yes         yes    no       yes  ...              1   \n",
              "1             no       yes         yes   yes       yes  ...              1   \n",
              "2            yes       yes         yes   yes       yes  ...              1   \n",
              "3             no       yes          no    no       yes  ...              1   \n",
              "4            yes       yes         yes   yes       yes  ...              1   \n",
              "...          ...       ...         ...   ...       ...  ...            ...   \n",
              "1823         NaN        no          no    no        no  ...              1   \n",
              "1824          no       yes         yes   yes        no  ...              1   \n",
              "1825          no       yes          no   yes       yes  ...              1   \n",
              "1826         yes       yes         yes   yes        no  ...              1   \n",
              "1827          no       yes         yes   yes        no  ...              1   \n",
              "\n",
              "     tb_predictions tb_predictions1  age meters_height   bmi  smear_all  \\\n",
              "0          0.654549        0.345451   31          1.62  24.0        neg   \n",
              "1          0.438112        0.561888   58          1.64  14.0        neg   \n",
              "2          0.414009        0.585991   24          1.83  16.0        neg   \n",
              "3          0.607053        0.392947   25          1.70  21.0        neg   \n",
              "4          0.401624        0.598376   30          1.70  20.0        neg   \n",
              "...             ...             ...  ...           ...   ...        ...   \n",
              "1823       0.846709        0.153291   24          1.58  26.0        neg   \n",
              "1824       0.842927        0.157073   21          1.56  22.0        neg   \n",
              "1825       0.783166        0.216834   47          1.70  21.0        neg   \n",
              "1826       0.764668        0.235332   23          1.65  20.0        neg   \n",
              "1827       0.841721        0.158279   18          1.67  19.0        neg   \n",
              "\n",
              "       type_tb ground_truth_tb facility_code  \n",
              "0      No TBdx             neg           Kan  \n",
              "1      No TBdx             neg           Kan  \n",
              "2      No TBdx             neg           Cha  \n",
              "3      No TBdx             neg          Chai  \n",
              "4      No TBdx             neg           Kan  \n",
              "...        ...             ...           ...  \n",
              "1823   No TBdx             neg           Cha  \n",
              "1824   No TBdx             neg           Cha  \n",
              "1825   No TBdx             neg           Kan  \n",
              "1826   No TBdx             neg           Cha  \n",
              "1827   No TBdx             neg          Chai  \n",
              "\n",
              "[1828 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db9a798f-d808-4cd9-83d2-009123e8c4fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>consent_obtained</th>\n",
              "      <th>barcode</th>\n",
              "      <th>coughdur</th>\n",
              "      <th>cough_productive</th>\n",
              "      <th>haemoptysis</th>\n",
              "      <th>chestpain</th>\n",
              "      <th>shortbreath</th>\n",
              "      <th>fever</th>\n",
              "      <th>ngtsweats</th>\n",
              "      <th>...</th>\n",
              "      <th>tb_class_index</th>\n",
              "      <th>tb_predictions</th>\n",
              "      <th>tb_predictions1</th>\n",
              "      <th>age</th>\n",
              "      <th>meters_height</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smear_all</th>\n",
              "      <th>type_tb</th>\n",
              "      <th>ground_truth_tb</th>\n",
              "      <th>facility_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>01-399-0258</td>\n",
              "      <td>1-2wks</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.654549</td>\n",
              "      <td>0.345451</td>\n",
              "      <td>31</td>\n",
              "      <td>1.62</td>\n",
              "      <td>24.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Kan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>01-399-1081</td>\n",
              "      <td>&lt;1wk</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.438112</td>\n",
              "      <td>0.561888</td>\n",
              "      <td>58</td>\n",
              "      <td>1.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Kan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>02-399-0856</td>\n",
              "      <td>&lt;1wk</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414009</td>\n",
              "      <td>0.585991</td>\n",
              "      <td>24</td>\n",
              "      <td>1.83</td>\n",
              "      <td>16.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Cha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "      <td>03-399-0290</td>\n",
              "      <td>1-2wks</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.607053</td>\n",
              "      <td>0.392947</td>\n",
              "      <td>25</td>\n",
              "      <td>1.70</td>\n",
              "      <td>21.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Chai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>01-399-0744</td>\n",
              "      <td>&lt;1wk</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.401624</td>\n",
              "      <td>0.598376</td>\n",
              "      <td>30</td>\n",
              "      <td>1.70</td>\n",
              "      <td>20.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Kan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1823</th>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "      <td>02-399-0239</td>\n",
              "      <td>no cough</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>0.153291</td>\n",
              "      <td>24</td>\n",
              "      <td>1.58</td>\n",
              "      <td>26.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Cha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1824</th>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "      <td>02-399-0214</td>\n",
              "      <td>&lt;1wk</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.842927</td>\n",
              "      <td>0.157073</td>\n",
              "      <td>21</td>\n",
              "      <td>1.56</td>\n",
              "      <td>22.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Cha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1825</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>01-399-0973</td>\n",
              "      <td>&lt;1wk</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.783166</td>\n",
              "      <td>0.216834</td>\n",
              "      <td>47</td>\n",
              "      <td>1.70</td>\n",
              "      <td>21.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Kan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>m</td>\n",
              "      <td>1</td>\n",
              "      <td>02-399-0711</td>\n",
              "      <td>&gt;4weeks</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.764668</td>\n",
              "      <td>0.235332</td>\n",
              "      <td>23</td>\n",
              "      <td>1.65</td>\n",
              "      <td>20.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Cha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "      <td>03-399-0118</td>\n",
              "      <td>3-4wks</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.841721</td>\n",
              "      <td>0.158279</td>\n",
              "      <td>18</td>\n",
              "      <td>1.67</td>\n",
              "      <td>19.0</td>\n",
              "      <td>neg</td>\n",
              "      <td>No TBdx</td>\n",
              "      <td>neg</td>\n",
              "      <td>Chai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1828 rows √ó 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db9a798f-d808-4cd9-83d2-009123e8c4fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db9a798f-d808-4cd9-83d2-009123e8c4fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db9a798f-d808-4cd9-83d2-009123e8c4fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db040802-162c-47b1-acef-20d791747255\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db040802-162c-47b1-acef-20d791747255')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db040802-162c-47b1-acef-20d791747255 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_adbd5413-1cef-492f-b129-d7e62565657a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_adbd5413-1cef-492f-b129-d7e62565657a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_values = df[\"ground_truth_tb\"].value_counts()\n",
        "print(count_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asd9eAILGneo",
        "outputId": "aeb22720-6d69-4501-e48e-a42b9ccc87ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ground_truth_tb\n",
            "neg    1623\n",
            "pos     205\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing**"
      ],
      "metadata": {
        "id": "U2MLMx73nOR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0_Raw**"
      ],
      "metadata": {
        "id": "EzP9BLkdRa_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Konfigurasi Path ===\n",
        "BASE_PATH = \"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia\"\n",
        "METADATA_PATH = os.path.join(BASE_PATH, \"Metadata and Codebook/GHAI_Final_Data_2023.csv\")\n",
        "\n",
        "INPUT_FOLDERS = [\n",
        "    \"Chainda South Phone A\", \"Chainda South Phone B\", \"Chainda South Phone C\",\n",
        "    \"Chawama Phone A\", \"Chawama Phone B\", \"Chawama Phone C\",\n",
        "    \"Kanyama Phone A\", \"Kanyama Phone B\", \"Kanyama Phone C\",\n",
        "    \"Audio-Recorder-Chainda-South\", \"Audio-Recorder-Chawama\", \"Audio-Recorder-Kanyama\"\n",
        "]\n",
        "\n",
        "OUTPUT_ROOT = os.path.join(BASE_PATH, \"0_Raw\")\n",
        "os.makedirs(os.path.join(OUTPUT_ROOT, \"pos\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_ROOT, \"neg\"), exist_ok=True)\n",
        "\n",
        "# === Muat Metadata CSV ===\n",
        "metadata_df = pd.read_csv(METADATA_PATH)\n",
        "metadata_df = metadata_df[['sex', 'barcode', 'anon_id', 'ground_truth_tb']]\n",
        "barcode_to_label = dict(zip(metadata_df['barcode'], metadata_df['ground_truth_tb']))\n",
        "\n",
        "# === Helper ===\n",
        "def parse_facility_tool(folder_name):\n",
        "    if folder_name.startswith(\"Audio-Recorder-\"):\n",
        "        parts = folder_name.split(\"-\")\n",
        "        facility = parts[-1]\n",
        "        if facility == \"South\":\n",
        "            facility = \"Chainda South\"\n",
        "        return facility, \"Audio Recorder\"\n",
        "    else:\n",
        "        parts = folder_name.split(\" Phone \")\n",
        "        facility = parts[0].strip()\n",
        "        tool = \"Phone \" + parts[1].strip()\n",
        "        return facility, tool\n",
        "\n",
        "# === Worker ===\n",
        "def process_file(args):\n",
        "    folder_in, fname = args\n",
        "    if not fname.lower().endswith(\".wav\"):\n",
        "        return None\n",
        "\n",
        "    barcode = os.path.splitext(fname)[0]\n",
        "    tb_label = barcode_to_label.get(barcode, None)\n",
        "    if tb_label is None:\n",
        "        return None\n",
        "\n",
        "    label = \"pos\" if str(tb_label).lower() in [\"positive\", \"1\", \"pos\"] else \"neg\"\n",
        "    src_path = os.path.join(BASE_PATH, folder_in, fname)\n",
        "\n",
        "    # --- Parse facility & tool ---\n",
        "    facility, tool = parse_facility_tool(folder_in)\n",
        "\n",
        "    # --- Mapping tool ke suffix ---\n",
        "    if \"Phone A\" in tool:\n",
        "        suffix = \"A\"\n",
        "    elif \"Phone B\" in tool:\n",
        "        suffix = \"B\"\n",
        "    elif \"Phone C\" in tool:\n",
        "        suffix = \"C\"\n",
        "    elif \"Audio Recorder\" in tool:\n",
        "        suffix = \"R\"\n",
        "    else:\n",
        "        suffix = \"X\"  # fallback\n",
        "\n",
        "    # --- Rename file output ---\n",
        "    out_fname = f\"{barcode}-{suffix}.wav\"\n",
        "    dst_path = os.path.join(OUTPUT_ROOT, label, out_fname)\n",
        "\n",
        "    try:\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        return {\n",
        "            \"barcode\": barcode,\n",
        "            \"file_name\": out_fname,\n",
        "            \"label\": label,\n",
        "            \"sex\": metadata_df.loc[metadata_df['barcode'] == barcode, 'sex'].values[0],\n",
        "            \"anon_id\": metadata_df.loc[metadata_df['barcode'] == barcode, 'anon_id'].values[0],\n",
        "            \"ground_truth_tb\": tb_label,\n",
        "            \"facility_code\": facility,\n",
        "            \"tool\": tool\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error copy {src_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Main ===\n",
        "def main():\n",
        "    # Hitung total file dulu\n",
        "    all_tasks = []\n",
        "    folder_to_tasks = {}\n",
        "    for folder_in in INPUT_FOLDERS:\n",
        "        full_folder_in_path = os.path.join(BASE_PATH, folder_in)\n",
        "        if not os.path.exists(full_folder_in_path):\n",
        "            print(f\"‚ö†Ô∏è Skip folder {full_folder_in_path}\")\n",
        "            continue\n",
        "\n",
        "        tasks = [(folder_in, fname) for fname in os.listdir(full_folder_in_path)]\n",
        "        if tasks:\n",
        "            folder_to_tasks[folder_in] = tasks\n",
        "            all_tasks.extend(tasks)\n",
        "\n",
        "    print(f\"üîç Total file ditemukan: {len(all_tasks)}\\n\")\n",
        "\n",
        "    NUM_PROCESSES = 2\n",
        "    results = []\n",
        "    with Pool(processes=NUM_PROCESSES) as pool:\n",
        "        for folder_in, tasks in folder_to_tasks.items():\n",
        "            print(f\"üìÇ Proses folder: {folder_in} ({len(tasks)} file)\")\n",
        "            for r in tqdm(pool.imap_unordered(process_file, tasks),\n",
        "                          total=len(tasks), desc=folder_in, leave=True):\n",
        "                if r is not None:\n",
        "                    results.append(r)\n",
        "\n",
        "    # simpan metadata\n",
        "    out_meta = pd.DataFrame(results)\n",
        "    out_meta.to_csv(os.path.join(OUTPUT_ROOT, \"metadata_raw.csv\"), index=False)\n",
        "    print(f\"\\n‚úÖ Selesai! Metadata tersimpan di {OUTPUT_ROOT}/metadata_raw.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "OvAZHAyPTk7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832c67fd-ff7a-4acd-a0bd-2076aa492960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Total file ditemukan: 1485\n",
            "\n",
            "üìÇ Proses folder: Chainda South Phone A (35 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chainda South Phone A: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [01:03<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Chainda South Phone B (35 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chainda South Phone B: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:46<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Chainda South Phone C (35 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chainda South Phone C: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:47<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Chawama Phone A (101 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chawama Phone A: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [02:56<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Chawama Phone B (101 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chawama Phone B: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [03:04<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Chawama Phone C (101 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chawama Phone C: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [03:12<00:00,  1.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Kanyama Phone A (262 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Kanyama Phone A: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 262/262 [07:57<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Kanyama Phone B (267 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Kanyama Phone B: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 267/267 [08:14<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Kanyama Phone C (267 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Kanyama Phone C: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 267/267 [08:22<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Audio-Recorder-Chainda-South (36 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Audio-Recorder-Chainda-South: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:14<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Audio-Recorder-Chawama (100 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Audio-Recorder-Chawama: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:28<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Proses folder: Audio-Recorder-Kanyama (145 file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Audio-Recorder-Kanyama: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 145/145 [00:47<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Selesai! Metadata tersimpan di /content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia/0_Raw/metadata_raw.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1_Segmentasi**"
      ],
      "metadata": {
        "id": "Rpbi7TvCpjjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Konfigurasi Path ===\n",
        "BASE_PATH = \"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia\"\n",
        "RAW_PATH = os.path.join(BASE_PATH, \"0_Raw\")\n",
        "META_RAW_PATH = os.path.join(RAW_PATH, \"metadata_raw.csv\")\n",
        "SEG_PATH = os.path.join(BASE_PATH, \"1_Segmented\")\n",
        "os.makedirs(os.path.join(SEG_PATH, \"pos\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(SEG_PATH, \"neg\"), exist_ok=True)\n",
        "\n",
        "META_OUT_PATH = os.path.join(SEG_PATH, \"metadata_segmented.csv\")\n",
        "\n",
        "# === Muat Metadata Raw ===\n",
        "meta_raw = pd.read_csv(META_RAW_PATH)\n",
        "\n",
        "# === Fungsi VAD ===\n",
        "def getVad(data, fs):\n",
        "    winlen, ovrlen, pre_coef, nfilter, nftt = 0.025, 0.01, 0.97, 20, 512\n",
        "    ftThres = 0.5\n",
        "    vadThres = 0.4\n",
        "    opts = 1\n",
        "\n",
        "    ft, flen, fsh10, nfr10 = speechproc.sflux(data, fs, winlen, ovrlen, nftt)\n",
        "    pv01 = np.zeros(nfr10)\n",
        "    pv01[np.less_equal(ft, ftThres)] = 1\n",
        "    pitch = deepcopy(ft)\n",
        "    pvblk = speechproc.pitchblockdetect(pv01, pitch, nfr10, opts)\n",
        "\n",
        "    ENERGYFLOOR = np.exp(-50)\n",
        "    b = np.array([0.9770, -0.9770])\n",
        "    a = np.array([1.0000, -0.9540])\n",
        "    fdata = lfilter(b, a, data, axis=0)\n",
        "\n",
        "    noise_samp, _, n_noise_samp = speechproc.snre_highenergy(\n",
        "        fdata, nfr10, flen, fsh10, ENERGYFLOOR, pv01, pvblk\n",
        "    )\n",
        "    for j in range(n_noise_samp):\n",
        "        fdata[round(noise_samp[j, 0]): round(noise_samp[j, 1]) + 1] = 0\n",
        "\n",
        "    vad_seg = speechproc.snre_vad(\n",
        "        fdata, nfr10, flen, fsh10, ENERGYFLOOR, pv01, pvblk, vadThres\n",
        "    )\n",
        "    return vad_seg\n",
        "\n",
        "# === Segmentasi ===\n",
        "def segment_audio(file_path):\n",
        "    X, sample_rate = librosa.load(file_path, sr=22050, mono=True)\n",
        "    fvad = getVad(X, sample_rate)\n",
        "\n",
        "    list_X, temp = [], []\n",
        "    for i in range(1, len(fvad)):\n",
        "        if fvad[i - 1] == 1:\n",
        "            len_sector = math.floor(len(X) / len(fvad))\n",
        "            start = (i - 1) * len_sector\n",
        "            for j in range(start, start + len_sector):\n",
        "                if j < len(X):\n",
        "                    temp.append(X[j])\n",
        "        if fvad[i - 1] == 1 and fvad[i] == 0:\n",
        "            list_X.append(temp)\n",
        "            temp = []\n",
        "    return np.array(list_X, dtype=object), sample_rate\n",
        "\n",
        "# === Worker ===\n",
        "def process_file(args):\n",
        "    file_path, barcode, label, row_dict = args\n",
        "    new_rows = []\n",
        "    try:\n",
        "        segments, sr = segment_audio(file_path)\n",
        "        for i, seg in enumerate(segments):\n",
        "            if len(seg) == 0:\n",
        "                continue\n",
        "            seg = np.asarray(seg, dtype=np.float32)\n",
        "            out_fname = f\"{barcode}_seg{i}.wav\"\n",
        "            out_path = os.path.join(SEG_PATH, label, out_fname)\n",
        "            sf.write(out_path, seg, sr)\n",
        "\n",
        "            new_row = row_dict.copy()\n",
        "            new_row[\"file_name\"] = out_fname\n",
        "            new_rows.append(new_row)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error {file_path}: {e}\")\n",
        "    return new_rows\n",
        "\n",
        "# === Main dengan Batch + Checkpoint ===\n",
        "def main(batch_size=100, n_workers=2):\n",
        "    # cek checkpoint\n",
        "    if os.path.exists(META_OUT_PATH):\n",
        "        done_meta = pd.read_csv(META_OUT_PATH)\n",
        "        # ambil barcode tanpa suffix _seg untuk checkpoint\n",
        "        done_files = set(done_meta[\"file_name\"].str.split(\"_seg\").str[0])\n",
        "        print(f\"üîÑ Resume mode, sudah ada {len(done_files)} file diproses\")\n",
        "    else:\n",
        "        done_files = set()\n",
        "\n",
        "    for label in [\"neg\", \"pos\"]:\n",
        "        folder_in = os.path.join(RAW_PATH, label)\n",
        "        files = [f for f in os.listdir(folder_in) if f.lower().endswith(\".wav\")]\n",
        "        print(f\"üîç {label.upper()} - {len(files)} files\")\n",
        "\n",
        "        # checkpoint ‚Üí skip yg sudah ada\n",
        "        files = [f for f in files if os.path.splitext(f)[0] not in done_files]\n",
        "\n",
        "        for i in range(0, len(files), batch_size):\n",
        "            batch_files = files[i:i+batch_size]\n",
        "            print(f\"‚ö° Batch {i//batch_size+1}/{math.ceil(len(files)/batch_size)} ({len(batch_files)} files)\")\n",
        "\n",
        "            tasks = []\n",
        "            for fname in batch_files:\n",
        "                # ambil barcode full tanpa tool suffix\n",
        "                base_name = os.path.splitext(fname)[0]        # \"01-399-1081-A\"\n",
        "                if \"-\" in base_name:\n",
        "                    barcode_only = base_name.rsplit(\"-\", 1)[0]  # \"01-399-1081\"\n",
        "                else:\n",
        "                    barcode_only = base_name\n",
        "\n",
        "                file_path = os.path.join(folder_in, fname)\n",
        "                row = meta_raw.loc[meta_raw['barcode'] == barcode_only]\n",
        "                if row.empty:\n",
        "                    print(f\"‚ö†Ô∏è Barcode {barcode_only} tidak ditemukan di metadata\")\n",
        "                    continue\n",
        "                row_dict = row.iloc[0].to_dict()\n",
        "                tasks.append((file_path, base_name, label, row_dict))  # gunakan base_name termasuk suffix tool\n",
        "\n",
        "            new_meta = []\n",
        "            with Pool(processes=n_workers) as pool:\n",
        "                for result in tqdm(pool.imap_unordered(process_file, tasks),\n",
        "                                   total=len(tasks), desc=f\"{label}\"):\n",
        "                    new_meta.extend(result)\n",
        "\n",
        "            # simpan hasil batch (append)\n",
        "            if new_meta:\n",
        "                df_out = pd.DataFrame(new_meta)\n",
        "                header = not os.path.exists(META_OUT_PATH)\n",
        "                df_out.to_csv(META_OUT_PATH, mode=\"a\", index=False, header=header)\n",
        "\n",
        "    print(f\"‚úÖ Semua selesai! Metadata di {META_OUT_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(batch_size=100, n_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP_-1FVRejx6",
        "outputId": "72b052b0-79bf-4a0d-d2f9-c70948b9fb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç NEG - 1073 files\n",
            "‚ö° Batch 1/11 (100 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "neg: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [24:14<00:00, 14.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Batch 2/11 (100 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "neg: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [23:53<00:00, 14.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Batch 3/11 (100 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "neg: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [25:40<00:00, 15.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Batch 4/11 (100 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "neg:  14%|‚ñà‚ñç        | 14/100 [04:32<24:06, 16.82s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2_Validasi Batuk dan Cleaning**"
      ],
      "metadata": {
        "id": "XtK-Ma2_Oime"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validasi Batuk\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Supress warnings dari librosa/tensorflow\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# === Konfigurasi path ===\n",
        "BASE_PATH = \"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia\"\n",
        "SEG_PATH = os.path.join(BASE_PATH, \"1_Segmented\")\n",
        "META_SEG_PATH = os.path.join(SEG_PATH, \"metadata_segmented.csv\")\n",
        "META_VALIDATED_PATH = os.path.join(SEG_PATH, \"metadata_validated.csv\")\n",
        "\n",
        "# === Load YAMNet & class map ===\n",
        "print(\"üì¶ Memuat model YAMNet...\")\n",
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "class_names = list(pd.read_csv(os.path.join(BASE_PATH, 'yamnet_class_map.csv'))['display_name'])\n",
        "\n",
        "# === Baca metadata segmented ===\n",
        "df = pd.read_csv(META_SEG_PATH)\n",
        "\n",
        "# Siapkan kolom baru\n",
        "cough_scores = []\n",
        "is_coughs = []\n",
        "\n",
        "# Proses file audio satu per satu\n",
        "print(f\"üîç Memproses {len(df)} file audio dari folder 1_Segmented...\")\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    label = row['label']      # 'pos' atau 'neg'\n",
        "    fname = row['file_name']  # nama file segment\n",
        "    file_path = os.path.join(SEG_PATH, label, fname)\n",
        "\n",
        "    try:\n",
        "        waveform, sr = librosa.load(file_path, sr=16000)\n",
        "        waveform = waveform.astype(np.float32)\n",
        "\n",
        "        scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "        scores_np = scores.numpy()\n",
        "\n",
        "        cough_index = class_names.index('Cough')\n",
        "        cough_score = float(np.max(scores_np[:, cough_index]))\n",
        "        is_cough = 1 if cough_score > 0.5 else 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Gagal memproses {file_path}: {e}\")\n",
        "        cough_score = 0.0\n",
        "        is_cough = 0\n",
        "\n",
        "    cough_scores.append(cough_score)\n",
        "    is_coughs.append(is_cough)\n",
        "\n",
        "# Tambahkan kolom baru ke dataframe\n",
        "df[\"cough_score\"] = cough_scores\n",
        "df[\"is_cough\"] = is_coughs\n",
        "\n",
        "# Simpan metadata hasil validasi\n",
        "df.to_csv(META_VALIDATED_PATH, index=False)\n",
        "print(f\"‚úÖ Metadata berhasil disimpan di {META_VALIDATED_PATH}\")"
      ],
      "metadata": {
        "id": "nGK4_3w8Smfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Suara Non Cough\n",
        "\n",
        "# === Konfigurasi Path ===\n",
        "BASE_PATH = \"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia\"\n",
        "SEG_PATH = os.path.join(BASE_PATH, \"1_Segmented\")\n",
        "CLEAN_PATH = os.path.join(BASE_PATH, \"2_Cleaned\")\n",
        "\n",
        "META_VALID_PATH = os.path.join(SEG_PATH, \"metadata_validated.csv\")\n",
        "META_CLEAN_PATH = os.path.join(CLEAN_PATH, \"metadata_cleaned.csv\")\n",
        "\n",
        "# === Load metadata validated ===\n",
        "df = pd.read_csv(META_VALID_PATH)\n",
        "\n",
        "# Filter hanya segmen yang valid (is_cough == 1)\n",
        "df_valid = df[df['is_cough'] == 1].copy()\n",
        "df_valid.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Buat folder target\n",
        "for label in [\"pos\", \"neg\"]:\n",
        "    os.makedirs(os.path.join(CLEAN_PATH, label), exist_ok=True)\n",
        "\n",
        "# === Worker untuk copy file (dipakai di Pool) ===\n",
        "def copy_worker(row):\n",
        "    label = row['label']        # kolom label ('pos'/'neg')\n",
        "    filename = row['file_name'] # nama file segment\n",
        "    src_path = os.path.join(SEG_PATH, label, filename)\n",
        "    dst_path = os.path.join(CLEAN_PATH, label, filename)\n",
        "    try:\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal menyalin {filename}: {e}\")\n",
        "        return False\n",
        "\n",
        "# === Main ===\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(processes=4) as pool:\n",
        "        results = list(tqdm(pool.imap(copy_worker, [row for _, row in df_valid.iterrows()]),\n",
        "                            total=len(df_valid),\n",
        "                            desc=\"üìÇ Menyalin audio valid\"))\n",
        "\n",
        "    # Simpan metadata cleaned\n",
        "    df_valid.to_csv(META_CLEAN_PATH, index=False)\n",
        "    print(f\"‚úÖ Metadata cleaned disimpan ke: {META_CLEAN_PATH}\")\n",
        "    print(f\"üìä Total berhasil: {results.count(True)}, gagal: {results.count(False)}\")"
      ],
      "metadata": {
        "id": "C5IBWByrcHOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3_Ekstraksi Fitur**"
      ],
      "metadata": {
        "id": "xRwLEXXZmmyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Konfigurasi Path ===\n",
        "BASE_PATH = \"/content/drive/My Drive/[3] Model ML TBCare/Dataset Google + CIDRZ Health AI Evaluation Zambia\"\n",
        "OUTPUT_PATH = \"3_Fitur\"\n",
        "\n",
        "labels_map = {'pos': 1, 'neg': 0}\n",
        "\n",
        "# --- Ekstraksi fitur ---\n",
        "def extract_features(X, sample_rate):\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "\n",
        "    # === Frame-wise features ===\n",
        "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)              # (40, T)\n",
        "    chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate)             # (12, T)\n",
        "    mel = librosa.feature.melspectrogram(y=X, sr=sample_rate)                # (128, T)\n",
        "    contrast = librosa.feature.spectral_contrast(S=stft, sr=sample_rate)     # (7, T)\n",
        "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate)  # (6, T)\n",
        "    centroid = librosa.feature.spectral_centroid(y=X, sr=sample_rate, n_fft=275)     # (1, T)\n",
        "    bandwidth = librosa.feature.spectral_bandwidth(y=X, sr=sample_rate, n_fft=275)   # (1, T)\n",
        "    flatness = librosa.feature.spectral_flatness(y=X, n_fft=275)             # (1, T)\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=X, sr=sample_rate, n_fft=275)       # (1, T)\n",
        "\n",
        "    # === Rangkuman statistik ===\n",
        "    def summarize(feat):\n",
        "        return np.concatenate([np.mean(feat, axis=1), np.std(feat, axis=1)])\n",
        "\n",
        "    return {\n",
        "        \"seq\": {\n",
        "            \"mfcc\": mfcc,\n",
        "            \"chroma\": chroma,\n",
        "            \"mel\": mel,\n",
        "            \"contrast\": contrast,\n",
        "            \"tonnetz\": tonnetz,\n",
        "            \"centroid\": centroid,\n",
        "            \"bandwidth\": bandwidth,\n",
        "            \"flatness\": flatness,\n",
        "            \"rolloff\": rolloff,\n",
        "        },\n",
        "        \"mean\": {\n",
        "            \"mfcc\": summarize(mfcc),\n",
        "            \"chroma\": summarize(chroma),\n",
        "            \"mel\": summarize(mel),\n",
        "            \"contrast\": summarize(contrast),\n",
        "            \"tonnetz\": summarize(tonnetz),\n",
        "            \"centroid\": summarize(centroid),\n",
        "            \"bandwidth\": summarize(bandwidth),\n",
        "            \"flatness\": summarize(flatness),\n",
        "            \"rolloff\": summarize(rolloff),\n",
        "        }\n",
        "    }\n",
        "\n",
        "def process_file(args):\n",
        "    file_path, label, root_dir = args\n",
        "    try:\n",
        "        X, sr = librosa.load(file_path, sr=None)\n",
        "        feats = extract_features(X, sr)\n",
        "        return {\n",
        "            \"mean\": {**feats[\"mean\"], \"label\": labels_map[label], \"source\": root_dir},\n",
        "            \"seq\": {**feats[\"seq\"], \"label\": labels_map[label], \"source\": root_dir}\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Kumpulkan file wav ---\n",
        "def collect_files():\n",
        "    all_files = []\n",
        "    for label in os.listdir(BASE_PATH):\n",
        "        label_dir = os.path.join(BASE_PATH, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for file_name in os.listdir(label_dir):\n",
        "                if file_name.endswith(\".wav\"):\n",
        "                    file_path = os.path.join(label_dir, file_name)\n",
        "                    all_files.append((file_path, label, BASE_PATH))\n",
        "    return all_files\n",
        "\n",
        "# --- Main ---\n",
        "def main():\n",
        "    all_files = collect_files()\n",
        "    results = []\n",
        "\n",
        "    with Pool(processes=10) as pool:\n",
        "        for res in tqdm(pool.imap_unordered(process_file, all_files),\n",
        "                        total=len(all_files),\n",
        "                        desc=\"Extracting features\",\n",
        "                        unit=\"file\"):\n",
        "            if res is not None:\n",
        "                results.append(res)\n",
        "\n",
        "    # --- Simpan hasil ---\n",
        "    for version in [\"mean\", \"seq\"]:\n",
        "        save_dir = os.path.join(OUTPUT_PATH, version)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        feature_keys = ['mfcc','chroma','mel','contrast','tonnetz','centroid','bandwidth','flatness','rolloff']\n",
        "        feature_arrays = {key: [r[version][key] for r in results] for key in feature_keys}\n",
        "        y_all = [r[version]['label'] for r in results]\n",
        "        sources = [r[version]['source'] for r in results]\n",
        "\n",
        "        # Save ke npy\n",
        "        for key in feature_keys:\n",
        "            np.save(\n",
        "                os.path.join(save_dir, f\"X_{key}.npy\"),\n",
        "                np.array(feature_arrays[key], dtype=object if version==\"seq\" else float)\n",
        "            )\n",
        "        np.save(os.path.join(save_dir, \"y.npy\"), np.array(y_all))\n",
        "        np.save(os.path.join(save_dir, \"source.npy\"), np.array(sources))\n",
        "\n",
        "        print(f\"‚úÖ Fitur {version} disimpan di: {save_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "neS04XV2mrOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analisis Fitur**"
      ],
      "metadata": {
        "id": "9BXpFCltmuuI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQ4678-pmyrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awLIYeuEmyjQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}